{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20211130_paper_review_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvTxhp5kme24"
      },
      "source": [
        "# **[논문 리뷰] A Word-Complexity Lexicon and A Neural Readability Ranking Model for Lexical Simplification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkRbmSGEmEeW"
      },
      "source": [
        "***\n",
        "**관련 Github 링크 : https://github.com/mounicam/lexical_simplification**\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_psWnhyjmxO7"
      },
      "source": [
        "## **0. Abstract**\n",
        "\n",
        "현재의 어휘 단순화 접근 방식은 인간의 판단과 항상 일치하지 않는 휴리스틱 및 말뭉치 수준 기능에 크게 의존합니다.\n",
        "우리는 15,000개의 영어 단어로 구성된 인간 등급의 단어 복잡도 사전을 만들고 주어진 단어나 구문의 복잡성을 측정하기 위해 이러한 인간 등급을 활용하는 가우시안 기반 특징 벡터화 레이어를 사용하여 새로운 신경 가독성 순위 모델을 제안합니다.\n",
        "우리 모델은 다양한 어휘 단순화 작업 및 평가 데이터 세트에 대해 최첨단 시스템보다 더 나은 성능을 보입니다.\n",
        "또한 우리의 모델을 PPDB(Paraphrase Database)에 적용하여 천만 개 이상의 의역 규칙을 단순화하는 어휘 리소스인 SimplePPDB++도 생성합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiQwihYunT5f"
      },
      "source": [
        "## **1. Introduction**\n",
        "\n",
        "어휘 단순화는 단어나 구의 복잡성, 특히 대체 의역을 사용하여 가독성을 측정하고 복잡성을 줄이는 방법과 관련된 중요한 하위 필드입니다.\n",
        "\n",
        "**파이프라인과 효과적으로 유사한 세 가지 주요 어휘 단순화 작업이 있습니다.**\n",
        "\n",
        "***\n",
        "\n",
        "(i) 문장에서 복잡한 단어를 식별하는 복잡한 단어 식별(Paetzold and Specia, 2016a; Yimam et al., 2017; Shardlow, 2013b).\n",
        "\n",
        "(ii) 복잡한 단어나 구에 대한 대안을 찾는 대체 생성(Glavas 및 ˇ Stajner ˇ, 2015; Coster 및 Kauchak, 2011).\n",
        "\n",
        "(iii) 단순성으로 의역의 순위를 매기는 것을 포함하는 대체 순위(Specia et al., 2012).\n",
        "\n",
        "***\n",
        "\n",
        "어휘 단순화는 또한 어린이(Kajiwara et al., 2013), 원어민이 아닌 사람(Petersen and Ostendorf, 2007; Pellow and Eskenazi, 2014)을 위한 읽기 지원과 같은 복잡한 단어의 대체 표현을 표시하는 것과 같이 현실 세계에서 실용적으로 사용됩니다. 일반 독자(Elhadad and Sutaria, 2007; Siddharthan 및 Katsos, 2010) 또는 읽기 장애가 있는 사람들(Rello et al., 2013).\n",
        "\n",
        "어휘 단순화에 대한 대부분의 현재 접근 방식은 단어 길이 및 말뭉치 기반 단어 빈도와 같은 말뭉치 통계 및 표면 수준 기능에 크게 의존합니다(§5 'Related Work 참조).\n",
        "\n",
        "가장 일반적으로 사용되는 두 가지 가정은 단순한 단어가 말뭉치에서 더 짧은 길이와 더 높은 빈도와 관련되어 있다는 것입니다.\n",
        "\n",
        "그러나 이러한 가정이 항상 정확한 것은 아니며 단순화 파이프라인에서 오류의 주요 원인이 되는 경우가 많습니다(Shardlow, 2014).\n",
        "\n",
        "예를 들어, 어리석음이라는 단어는 Google 1T Ngram 코퍼스에서 어리석음이 더 길고 덜 빈번하더라도 의미를 보존하는 대체 어리석음보다 간단합니다(Brants and Franz, 2006).\n",
        "\n",
        "사실, 우리는 PPDB2(Ganitkevitch et al., 2013)에서 무작위로 샘플링된 2272개의 의미 등가 단어 쌍 중 21%가 복잡한 단어보다 더 간단한 단어를 가지고 있는 반면 14%는 더 간단한 단어가 덜 자주 사용된다는 것을 발견했습니다.\n",
        "\n",
        "말뭉치와 표면 기반 방법의 피할 수 없는 단점을 완화하기 위해 우리는 간단하지만 놀랍도록 탐구되지 않은 아이디어를 탐구합니다. 즉, 인간이 단어의 복잡성을 평가한 15,000단어의 영어 사전을 만드는 것입니다.\n",
        "\n",
        "우리는 또한 가우시안 기반 특징 벡터화 레이어가 있는 새로운 신경 가독성 순위 모델을 제안합니다. 이 모델은 주어진 단어나 구문의 복잡성을 측정하기 위해 이러한 인간 등급과 기타 수치 특징을 효과적으로 활용할 수 있습니다. (사전 외부 및/또는 문장 맥락이 있는 것을 포함)\n",
        "\n",
        "우리 모델은 대체 순위에 대한 벤치마크 SemEval-2012 평가(Specia et al., 2012; Paetzold and Specia, 2017)에서 최신 기술을 훨씬 능가하며 수동으로 생성된 단어 복잡성 어휘를 사용하거나 사용하지 않은 피어슨 상관 계수는 각각 0.714 및 0.702입니다.\n",
        "\n",
        "우리는 또한 새로운 순위 모델을 적용하여 PPDB에 있는 많은 수의 의역 규칙 중에서 어휘 단순화(예: 기념 → 축하)를 식별하고 대체 생성에 대한 이전 작업에 비해 정확도가 향상되었습니다. 마지막으로 단어복잡성 어휘를 활용하여 복잡한 단어 식별을 위한 두 가지 공통 테스트 세트에 대한 새로운 최첨단 기술을 설정합니다(Paetzold and Specia, 2016a; Yimam et al., 2017).\n",
        "\n",
        "우리는 코드, 단어 복잡도 어휘, 1천만 개 이상의 의역 규칙의 어휘 리소스를 가독성 점수가 개선된(즉, SimplePPDB++) 모두 공개적으로 사용할 수 있도록 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTS5rGYhiz3n"
      },
      "source": [
        "## **2. Constructing A Word-Complexity Lexicon with Human Judgments**\n",
        "\n",
        "***\n",
        "**해석 : 인간의 판단으로 단어 복잡도 사전 구성하기**\n",
        "***\n",
        "\n",
        "우리는 먼저 인간 애노테이터가 평가한 단어 복잡도 점수를 사용하여 15,000개의 영어 단어로 구성된 사전을 구성했습니다.3 실제 더 큰 영어 어휘 크기에도 불구하고 Google 1T Ngram Corpus4에서 가장 자주 사용되는 15,000개의 영어 단어를 평가하는 것이 단순화 목적에 효과적이라는 것을 발견했습니다. (참조 §4)의 실험은 신경 순위 모델(§3)이 어휘 외의 단어나 구의 복잡성을 추정할 수 있기 때문입니다.\n",
        "\n",
        "우리는 11명의 비원어민이지만 유창한 영어 사용자에게 6점 Likert 척도로 단어를 평가하도록 요청했습니다.\n",
        "\n",
        "우리는 6점 체계를 통해 주석자가 자연스러운 2단계 접근 방식을 취할 수 있기 때문에 두 명의 주석자를 사용한 파일럿 실험에서 짝수 6점 척도가 5점 척도보다 더 잘 작동한다는 것을 발견했습니다. 먼저 단어가 간단한지 확인합니다. 또는 복합물; 그런 다음 '매우 단순함'(또는 '매우 복잡함'), '단순'(또는 '복잡함') 또는 '보통 단순함'(또는 '보통 복잡함') 여부를 결정합니다.\n",
        "\n",
        "대문자 버전이 여러 개인 단어(예: nature, Nature, NATURE)의 경우 가장 빈번한 형식을 주석자에게 표시했습니다. 우리는 또한 어노테이터에게 모호성, 컨텍스트 부족 또는 기타 이유로 인해 복잡성을 평가하는 데 문제가 있었던 단어를 표시하도록 요청했습니다.\n",
        "\n",
        "***\n",
        "**<논문 Table 1> 표가 삽입됩니다.**\n",
        "\n",
        "Word-Complexity lexicon은 영어 단어와 인간의 평가를 평균하여 얻은 복잡성 점수로 구성됩니다.\n",
        "\n",
        "A1, A2, A3, A4 및 A5는 6점 리커트 척도(1이 가장 단순하고 6이 가장 복잡함)에서 5개의 다른 주석에 의한 등급입니다.\n",
        "***\n",
        "\n",
        "모든 주석가들은 어려움이 거의 없다고 보고했으며, 생물학에서 곤충으로서의 의미나 컴퓨터 소프트웨어의 오류에 관계없이 버그라는 단어가 간단하다는 가능한 이유를 설명했습니다.\n",
        "\n",
        "고용된 애노테이터를 통해 대부분의 애노테이터가 더 나은 일관성을 위해 15,000단어의 절반 또는 전체 목록을 완성하도록 할 수 있었고 각 단어에 대해 5-7개의 등급을 수집할 수 있었습니다. 대부분의 주석가는 1,000단어를 평가하는 데 약 2-2.5시간이 걸렸습니다.\n",
        "\n",
        "**<논문 Table 1>**에서는 인간 평가와 함께 사전의 몇 가지 예를 보여줍니다.\n",
        "\n",
        "주석 품질을 평가하기 위해 각 주석의 주석과 나머지 주석의 평균 간의 Pearson 상관 계수를 계산했습니다(Agirre et al., 2014).\n",
        "\n",
        "최종 단어 복잡도 사전의 경우 각 단어에 대한 인간 평가의 평균을 취하고 나머지 평가의 평균과 2 이상의 차이를 보이는 단어(약 3%)를 버립니다.\n",
        "\n",
        "전체 애노테이터 간 일치는 외부 등급을 버린 후 0.55에서 0.64로 향상되었습니다.\n",
        "\n",
        "대부분의 불일치에 대해 한 주석자의 등급과 나머지 주석의 평균은 상당히 비슷했습니다. 차이는 주석의 47%에 대해 ≤ 0.5입니다. 주석의 78%에 대해 ≤ 1.0; 6점 척도에서 주석의 93%에 대해 ≤ 1.5입니다.\n",
        "\n",
        "우리는 의도적으로 다른 모국어의 어노테이터를 고용했는데, 이것이 판단의 차이에 기여했을 수 있습니다.\n",
        "\n",
        "추가 조사와 가능한 크라우드소싱 주석은 향후 작업에 남겨둡니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgZbtcDrq2iN"
      },
      "source": [
        "## **3. Neural Readability Ranking Model for Words and Phrases**\n",
        "\n",
        "***\n",
        "**해석 : 단어 및 구문에 대한 신경 가독성 순위 모델**\n",
        "***\n",
        "\n",
        "사전 내부 또는 외부에서 주어진 단어 또는 구의 복잡성을 예측하기 위해 생성된 단어 복잡성 사전을 활용하고 컨텍스트(가능한 경우)를 고려하여 성능을 더욱 향상시킬 수 있는 신경 가독성 순위 모델을 제안합니다.\n",
        "\n",
        "우리 모델은 가우시안 기반 벡터화 계층을 사용하여 수치적 특징을 보다 효과적으로 활용하고 단어 복잡도 어휘의 유무에 관계없이 여러 어휘 단순화 작업에 대한 최첨단 접근 방식을 능가할 수 있습니다.\n",
        "\n",
        "이 섹션에서는 일반 모델 프레임워크를 설명하고 실험 섹션(§4)에서는 작업별 구성에 대해 설명합니다.\n",
        "\n",
        "###  **[1] Neural Readability Ranker (NRR)**\n",
        "\n",
        "***\n",
        "**<그림 1>이 삽입됩니다.**\n",
        "\n",
        "**설명 : 신경 가독성 순위(NRR) 모델**\n",
        "***\n",
        "\n",
        "한 쌍의 단어/구 hwa, wbi가 입력으로 주어지면 우리 모델은 wa와 wb의 상대적 복잡성 P(y|hwa, wbi)를 나타내는 실수를 출력하는 것을 목표로 합니다.\n",
        "출력 값이 음수이면 wa는 wb보다 간단하고 그 반대의 경우도 마찬가지입니다.\n",
        "\n",
        "**<그림 1>**은 아래 세 가지 주요 구성 요소를 강조하는 순위 모델의 일반적인 아키텍처를 보여줍니다.\n",
        "\n",
        "1. 각 입력 f(wa) 및 f(wb) 및 쌍별 특성 f(hwa, wbi)에 대해 어휘 및 말뭉치 기반 특성을 생성하는 입력 특성 추출 계층(§3.2). 우리는 또한 수치적 특징과 이진 지표로 모델에 단어-복잡성 어휘를 주입합니다.\n",
        "\n",
        "2. 사전 점수 및 n-그램 확률과 같은 각 수치 특징을 일련의 가우스 방사형 기저 함수에 의한 벡터 표현으로 변환하는 가우시안 기반 특징 벡터화 계층(§3.3).\n",
        "\n",
        "3. 다른 어휘 단순화 작업(§4)에 모델을 적용하는 하나의 작업별 출력 노드로 회귀를 수행하는 피드-포워드 신경망.\n",
        "\n",
        "우리 모델은 먼저 각 입력 단어 또는 구를 병렬로 처리하여 벡터화된 특징을 생성합니다. 그런 다음 모든 기능이 공동 피드-포워드 신경망에 공급됩니다.\n",
        "\n",
        "### **[2] Features**\n",
        "\n",
        "우리는 단어 복잡성 어휘, 어휘 및 말뭉치 기능(Pavlick 및 Callison-Burch, 2016) 및 연어 기능(Paetzold 및 Specia, 2017)의 평가 점수 조합을 사용합니다.\n",
        "\n",
        "각 입력 단어 또는 구에 대해 두 가지 기능을 추가하여 단어 복잡도 사전을 NRR 모델에 주입합니다.\n",
        "\n",
        "하나는 사전에 단어(여러 단어 구에서 가장 긴 단어)가 있음을 나타내는 0-1 이진 기능입니다. (해당 단어 복잡도 점수와 연관)\n",
        "\n",
        "어휘가 아닌 단어의 경우 두 기능 모두 값이 0입니다. 해당되는 경우 표제어 단어의 복잡도 점수로 백오프합니다.\n",
        "\n",
        "우리는 또한 다음 기능을 추출합니다: 단어 및 문자 측면에서 구문 길이, 음절 수, Google Ngram 코퍼스에 대한 빈도(Brants and Franz, 2006), 일반 Wikipedia에 대한 Simple Wikipedia의 상대 빈도(Pavlick 및 Nenkova , 2015) SubIMDB 코퍼스(Paetzold and Specia, 2016c)에서 훈련된 5그램 언어 모델의 ngram 확률은 어휘 단순화에 잘 작동하는 것으로 나타났습니다.\n",
        "\n",
        "단어 w에 대해 w의 왼쪽과 오른쪽에 있는 2의 컨텍스트 창 내에서 가능한 모든 n-gram의 언어 모델 확률을 취합니다. w가 여러 단어로 된 구인 경우 w를 가능한 n-gram으로 나누고 특정 컨텍스트 창에 대한 확률을 평균화합니다.\n",
        "\n",
        "단어/구 hwa, wbi의 입력 쌍에 대해 개별 특성 f(w1), f(w2) 및 차이점 f(wa)-f(wb)를 포함합니다. 또한 코사인 유사성 cos(-→wa, −→wb) 및 입력 단어의 word2vec(Mikolov et al., 2013) 임베딩 간의 차이 −→wa −−→wb를 포함하는 쌍별 특성 f(hwa, wbi)를 사용합니다.\n",
        "\n",
        "여러 단어로 된 구에 대한 임베딩은 구에 있는 모든 단어의 임베딩을 평균화하여 얻습니다. 우리는 word2vec 패키지의 일부로 출시된 Google 뉴스 자료에서 사전 훈련된 300차원 임베딩을 사용합니다.\n",
        "\n",
        "### **[3] Vectorizing Numerical Features via Gaussian Binning**\n",
        "\n",
        "***\n",
        "**해석 : 가우스 비닝을 통한 수치적 특징 벡터화**\n",
        "***\n",
        "\n",
        "우리의 모델은 어휘 단순화를 위한 이전의 많은 접근 방식과 마찬가지로 주로 수치적 특징에 의존합니다. 이러한 연속적인 특성은 네트워크에 직접 공급될 수 있지만 특성 값의 서로 다른 간격 사이의 미묘한 관련성을 완전히 활용하는 것이 도움이 됩니다.\n",
        "\n",
        "우리는 부드러운 비닝 접근 방식을 채택하고 여러 가우스 방사형 기저 함수를 적용하여 각 수치 특징을 벡터 표현으로 투영합니다.\n",
        "각 특성 f에 대해 값 범위 [fmin, fmax]를 k개의 빈으로 균등하게 나누고 평균 μj(j ∈ {1, 2, ... , k})를 중심에 두고 각 빈에 대한 가우스 함수를 배치합니다. 빈 및 표준 편차 σ.\n",
        "\n",
        "***\n",
        "**We specify~ 부터는 수식이 너무 많아 작성하기 어려워 보류**\n",
        "***\n",
        "\n",
        "### **[4] Training and Implementation Details**\n",
        "\n",
        "***\n",
        "**해석 : 훈련 및 구현 세부 정보**\n",
        "***\n",
        "\n",
        "우리는 PyTorch 프레임워크를 사용하여 입력 레이어, 각 레이어에 8개의 노드가 있는 3개의 은닉 레이어 및 tanh 활성화 함수, 단일 노드 선형 출력 레이어로 구성된 NRR 모델을 구현합니다.\n",
        "\n",
        "훈련 목표는 평균 제곱 오차(MSE)를 최소화하는 것입니다. 여기서 yi 및 yˆi는 hwa, wbi의 실제 및 예측 상대 복잡도 점수이며, 이는 다양한 어휘 단순화 작업 및 데이터 세트에 맞게 구성할 수 있습니다. m은 훈련 예제의 수입니다. , θ는 NRR 모델의 매개변수 집합입니다.\n",
        "\n",
        "최적화를 위해 Adam 알고리즘(Kingma and Ba, 2014)을 사용하고 과적합을 방지하기 위해 0.2의 드롭아웃을 적용합니다. (§4.1) 및 (§4.2)의 실험에 대해 비율을 각각 0.0005 및 0.001로 설정했습니다.\n",
        "\n",
        "***\n",
        "**<그림 2>가 삽입됩니다.**\n",
        "\n",
        "**설명 : 가우스 방사형 기저 함수를 적용하여 10차원 표현으로 벡터화된 단어-복잡성 어휘집에서 300개의 무작위 단어의 1.0에서 5.0 사이의 복잡성 점수의 t-SNE 시각화를 나타낸 그림**\n",
        "***\n",
        "\n",
        "가우스 비닝 레이어의 경우 광범위한 매개변수 조정 없이 빈 수 k를 10으로, γ를 0.2로 설정합니다. **<그림 2>**와 같이 각 실험에 대해 100 Epoch의 결과를 보고합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lecHCVDBaTXa"
      },
      "source": [
        "## **4. Lexical Simplification Applications**\n",
        "\n",
        "***\n",
        "**해석 : 어휘 단순화 응용**\n",
        "***\n",
        "\n",
        "어휘 단순화 연구 분야는 전통적으로 여러 하위 작업과 데이터 세트를 연구하기 때문에 새로 생성된 어휘 및 NRR(신경 가독성 순위) 모델의 효율성을 입증하기 위한 일련의 실험을 제시합니다.\n",
        "\n",
        "### **[1] Substitution Ranking (SR)**\n",
        "\n",
        "문장의 대상 복합 단어와 후보 대체 세트로 구성된 인스턴스가 주어지면 대체 순위 지정 작업의 목표는 후보의 단순성 순서로 순위를 매기는 것입니다. 이 섹션에서는 제안된 NRR 모델이 단어 복잡도 사전을 사용하거나 사용하지 않고 이 작업에서 최첨단 신경 모델보다 성능이 우수함을 보여줍니다.\n",
        "\n",
        "**<데이터>**\n",
        "\n",
        "평가를 위해 SemEval 2012(Specia et al., 2012)의 English Lexical Simplification 공유 작업의 데이터 세트를 사용합니다. 훈련 및 테스트 세트는 각각 300개 및 1,710개의 인스턴스로 구성되며 총 201개의 대상 단어(모두 단일 단어, 대부분 다의어)와 각각 10개의 다른 문장으로 구성됩니다.\n",
        "\n",
        "그러한 경우의 한 가지 예는 문맥에 복잡한 대상 단어를 포함합니다.\n",
        "***\n",
        "**When you think about it, that’s pretty terrible.**\n",
        "***\n",
        "\n",
        "그리고 후보 대체 세트 {나쁜, 끔찍한, 개탄스러운}.\n",
        "\n",
        "각 인스턴스에는 순위가 매겨질 최소 2명과 평균 5명의 후보자가 포함됩니다. 데이터 세트에는 총 10034개의 후보가 있으며, 그 중 88.5%는 단어 복잡도 어휘집에 포함되고 9.9%는 다중 단어 구입니다(3438개의 고유 후보가 81.8%의 어휘 및 20.2%의 다중 단어).\n",
        "\n",
        "**<NRR 모델의 태스크별 설정>**\n",
        "\n",
        "우리는 NRR 모델을 모든 쌍의 후보 hca, 후보 집합의 cbi를 입력으로 사용하고 순위 차이 ra-rb를 groundtruth 레이블로 훈련합니다.\n",
        "\n",
        "이러한 각 쌍에 대해 hcb, 입력으로 cai 및 레이블로 rb - ra가 있는 다른 훈련 인스턴스도 포함합니다.\n",
        "\n",
        "후보 집합 C가 있는 테스트 인스턴스가 주어지면 다음과 같이 후보의 순위를 매깁니다. 모든 후보 hca, cbi 쌍에 대해 모델은 상대 복잡성 점수 S(ca, cb)를 예측합니다. 그런 다음 쌍별 점수를 집계하여 각 후보에 대한 단일 점수 R(ca) = P ca6=cb∈C S(ca, cb)를 계산하고 이러한 점수의 오름차순으로 후보의 순위를 지정합니다.\n",
        "\n",
        "**<기존 방식과의 비교>**\n",
        "\n",
        "***\n",
        "**<논문 Table 2> 표가 삽입됩니다.**\n",
        "\n",
        "**설명 : SemEval 2012의 English Lexical Simplification 공유 작업에 대한 대체 순위 평가. 당사의 NRR(신경 가독성 순위) 모델과 최신 신경 모델(Paetzold and Specia, 2017) 및 기타 모델의 P@1 및 Pearson 상관 관계 행동 양식. *는 최고 성능 기준선과 비교한 통계적 유의성(p < 0.05)을 나타냅니다(Paetzold and Specia, 2017).**\n",
        "***\n",
        "\n",
        "SemEval 2012 데이터 세트에서 가장 잘 보고된 결과로 대체 순위를 위해 최첨단 신경 모델(Paetzold and Specia, 2017)과 비교합니다.\n",
        "\n",
        "우리의 기준선에는 몇 가지 다른 기존 방법도 포함되어 있습니다. Biran et al. (2011), Kajiwara et al. (2013), 그리고 Glavas & Stajner (ˇ 2015)는 WordNet의 말뭉치 통계 및 의미론적 유사성 측정과 같은 다양한 정보를 결합하기 위해 신중하게 설계된 휴리스틱 채점 기능을 사용합니다. Horn et al. (2014) 및 Boundary Ranker(Paetzold 및 Specia, 2015)는 각각 지도 SVM 순위 모델과 다양한 기능을 가진 쌍별 선형 분류 모델을 사용합니다.\n",
        "\n",
        "이 모든 방법은 LEXenstein 툴킷(Paetzold and Specia, 2015)의 일부로 구현되었으며 여기에서 실험적 비교에 사용합니다. 또한 SVM 기반 순위를 사용한 SemEval 2012 참가자 중 최고의 시스템(Jauhar and Specia, 2012)과도 비교합니다.\n",
        "\n",
        "**<결과>**\n",
        "\n",
        "**<논문 Table 2>**는 NRR 모델의 성능을 Paetzold and Specia(2017)가 보고한 최신 결과와 비교합니다. 가장 단순한 후보(P@1)의 정밀도와 Pearson 상관 관계를 사용하여 성능을 측정합니다.\n",
        "\n",
        "P@1은 SemEval 2012 English Lexical Simplification 작업의 공식 메트릭인 TRank(Specia et al., 2012)와 동일합니다.\n",
        "\n",
        "P@1이 접근 방식의 실용적인 유용성을 포착하는 반면, Pearson 상관 관계는 시스템의 순위가 인간의 판단과 얼마나 잘 상관되는지를 나타냅니다.\n",
        "\n",
        "우리는 작은 훈련 세트에 대한 과적합을 피하기 위해 word2vec 임베딩 기능을 제외하고 §3.2에 언급된 모든 기능(NRRall)으로 NRR 모델을 훈련합니다. 우리의 전체 모델(NRRall+binning+W C)은 두 측정 모두에 대해 최신 기술보다 통계적으로 유의한 개선을 보여줍니다.\n",
        "\n",
        "모든 성능 메트릭에 적용할 수 있는 paired bootstrap test(Berg-Kirkpatrick et al., 2012; Efron and Tibshirani, 1993)를 사용합니다. 우리는 또한 Gaussian 기반 feature vectorization layer(+binning) 및 word-complexity lexicon(+WC)의 효율성을 보여주기 위해 ablation 실험을 수행했습니다.\n",
        "\n",
        "### **[2] SimplePPDB++**\n",
        "\n",
        "***\n",
        "**<논문 Table 3> 표가 삽입됩니다.**\n",
        "\n",
        "**설명 : SimplePPDB++에는 NRRall+binning+WC 모델에 의해 가독성 순위 점수가 개선된 어휘 및 구 의역이 포함되어 있습니다. SimplePPDB의 이전 작업(Pavlick 및 Callison-Burch, 2016)과 비교하여 여러 입력 단어/구에 대해 SimplePPDB++에 따라 상위 5개 순위 단순화가 표시됩니다.**\n",
        "***\n",
        "**<논문 Table 4> 표가 삽입됩니다.**\n",
        "\n",
        "**설명 : SimplePPDB 및 기타 기준선과 비교하여 SimplePPDB++를 생성하는 데 사용된 NRR(신경 가독성 순위) 모델의 교차 검증 정확도 및 정밀도. P+1은 '단순화' 규칙의 정밀도를 나타내고 P−1은 '복잡한' 규칙의 정밀도를 나타냅니다. * 최고 성능 기준선과 비교한 통계적 유의성(p < 0.05)을 나타냅니다(Pavlick 및 Callison-Burch, 2016).**\n",
        "***\n",
        "\n",
        "또한 NRR 모델을 적용하여 Paraphrase Database(PPDB)에서 어휘 및 구의 의역 규칙의 순위를 지정하고(Pavlick et al., 2015) 좋은 단순화를 식별할 수 있습니다(<논문 Table 3>의 예 참조).\n",
        "\n",
        "결과 어휘 리소스인 SimplePPDB++에는 '단순화', '복잡화' 또는 '무의미/차이 없음' 범주의 가독성 점수와 함께 PPDB 2.0의 XL 버전에 있는 모든 1310만 어휘 및 구 의역 규칙이 포함되어 있어 유연한 절충이 가능합니다. (고품질 및 높은 범위의 의역 사이)\n",
        "\n",
        "이 섹션에서는 3원 로지스틱 회귀 분류기를 사용한 이전 버전의 SimplePPDB(Pavlick and Callison-Burch, 2016)와 비교하여 SimplePPDB++를 생성하는 데 사용한 NRR 모델의 효율성을 보여줍니다.\n",
        "\n",
        "다음 섹션에서는 대체 생성 작업을 위한 SimplePPDB++의 유틸리티를 보여줍니다.\n",
        "\n",
        "**<NRR 모델의 태스크별 설정>**\n",
        "\n",
        "우리는 훈련 및 테스트를 위해 SimplePPDB와 동일한 11,829개의 패러프레이즈 규칙의 수동 레이블이 지정된 데이터를 사용합니다. 이 중 26.5%는 '단순화', 26.5%는 '복잡', 47%는 '무의미/무관심'으로 레이블이 지정되었습니다.\n",
        "\n",
        "NRR 모델을 회귀 문제로 처리하여 3방향 분류를 수행하도록 조정합니다.\n",
        "\n",
        "훈련 중에 우리는 정답 레이블을 다음과 같이 지정합니다. 의역 규칙이 '복잡한' 클래스에 속하면 y = -1, 규칙이 '단순화' 클래스에 속하면 y = +1, 그렇지 않으면 y = 0입니다.\n",
        "\n",
        "예측을 위해 네트워크는 단일 실수 값 출력 yˆ ∈ [−1, 1]를 생성한 다음 평가를 위한 값 범위를 기반으로 3개 클래스 레이블에 매핑됩니다. 값 범위에 대한 임계값은 -0.4 및 0.4이며 교차 검증을 통해 선택됩니다.\n",
        "\n",
        "**<기존 방식과의 비교>**\n",
        "\n",
        "SimplePPDB++를 생성하는 데 사용된 NRR(신경 가독성 순위) 모델을 다중 클래스 로지스틱 회귀 모델을 사용하는 SimplePPDB와 비교합니다. 또한 word2vec 임베딩 기능만 있는 로지스틱 회귀를 사용하는 W2V를 비롯한 여러 다른 기준선을 사용합니다.\n",
        "\n",
        "**<결과>**\n",
        "\n",
        "이전 작업(Pavlick 및 Callison-Burch, 2016)의 평가 설정에 따라 10겹 교차 검증을 통해 정확도와 정밀도를 비교합니다.\n",
        "\n",
        "폴드는 훈련 및 테스트 어휘가 분리되는 방식으로 구성됩니다. 표 4는 SimplePPDB 및 기타 기준과 비교한 우리 모델의 성능을 보여줍니다.\n",
        "\n",
        "<논문 Table 4>는 SimplePPDB 및 기타 기준과 비교한 우리 모델의 성능을 보여줍니다. 컨텍스트가 없는 PPDB에서 의역 규칙을 분류할 때 컨텍스트 기능을 제외하고 §3.2의 모든 기능(NRRall)을 사용합니다.\n",
        "\n",
        "SimplePPDB는 동일한 기능과 POS 태그, 문자 유니그램 및 바이그램과 같은 추가 개별 기능을 사용했습니다.\n",
        "\n",
        "가우스 비닝(NRRall+binning)을 사용하는 신경 가독성 순위 모델 단독으로 더 적은 기능을 사용하면서 더 나은 정확도와 정밀도를 달성합니다.\n",
        "\n",
        "어휘(NRRall+binning+W C)를 활용하면 페어링된 부트스트랩 테스트를 기반으로 하는 SimplePPDB 순위에 비해 통계적으로 유의미한 개선이 나타납니다.\n",
        "\n",
        "정확도는 3.2점, '단순화' 클래스의 정밀도는 7.4점, '복잡한' 클래스의 정밀도는 4.0점 향상됩니다.\n",
        "\n",
        "### **[3] Substitution Generation (SG)**\n",
        "\n",
        "***\n",
        "**해석 : 대체 생성**\n",
        "***\n",
        "**<논문 Table 5> 표가 삽입됩니다.**\n",
        "\n",
        "**설명 : Mean Average Precision, Precision@1 및 각 방법에 대한 대상당 생성된 평균 의역 수를 사용한 대체 생성 평가. n은 모델이 0개 이상의 후보를 생성한 대상 복합 단어/구의 수입니다. Kauchak은 가장 적은 수의 후보자를 생성하기 때문에 MAP에 이점이 있습니다. Glavas는 기술적으로 어휘만큼 많은 단어/구를 생성할 수 있기 때문에 '-'로 표시됩니다.**\n",
        "***\n",
        "\n",
        "대체 생성은 어휘 단순화에서 가장 도전적인 연구 문제로, 각 대상 복합 단어/구에 대한 후보 대체를 생성한 다음 대체 순위를 매기는 것을 포함합니다.\n",
        "\n",
        "주요 초점은 더 나은 순위를 가질 뿐만 아니라 더 중요한 것은 더 많은 수의 단순화 대체가 생성되도록 하는 것입니다.\n",
        "\n",
        "이것은 SimplePPDB++의 유용성과 이를 생성하는 데 사용한 NRR 순위 모델의 효율성, 그리고 그러한 어휘 자원이 향후 작업에서 종단 간 문장 단순화 시스템 개발에 얼마나 도움이 될 수 있는지를 보여주기 위한 보다 현실적인 평가입니다(Narayan and Gardent, 2016; Zhang and Lapata, 2017).\n",
        "\n",
        "**<데이터>**\n",
        "\n",
        "뉴스 기사의 Newsela Simplification Corpus(Xu et al., 2015)에서 샘플링된 100개의 고유한 대상 단어/구를 포함하는 (Pavlick and Callison-Burch, 2016)의 데이터 세트를 사용하고 동일한 평가 절차를 따릅니다. 생성된 대체가 좋은 단순화인지 평가하기 위해 두 명의 주석에게 요청합니다.\n",
        "\n",
        "**<기존 방식과의 비교>**\n",
        "\n",
        "우리는 기존의 여러 방법과 비교하여 SimplePPDB++에 의해 생성된 대체의 정확성을 평가합니다. Glavas( ˇ Glavas 및 ˇ Stajner ˇ , 2015), Kauchak(Coster and Kauchak, 2011), WordNet Generator(Devlin and Tait, 1998; Carroll et al. ., 1999) 및 SimplePPDB(Pavlick 및 CallisonBurch, 2016). Glavas는 GloVe(Pennington et al., 2014) 단어 벡터 공간에서 ˇ 유사성 점수가 가장 높은 후보를 얻습니다.\n",
        "\n",
        "Kauchak의 생성기는 Simple Wikipedia 및 일반 Wikipedia 병렬 코퍼스 및 자동 단어 정렬을 기반으로 합니다.\n",
        "WordNet 기반 생성기는 단순히 WordNet에서 단어의 동의어를 사용합니다(Miller, 1995).\n",
        "기존의 모든 방법에 대해 SVM 기반 순위를 사용한 구현(Pavlick and Callison-Burch, 2016)을 기반으로 결과를 보고합니다.\n",
        "\n",
        "SimplePPDB 및 SimplePPDB++ 모두에서 추출된 후보는 PPDB 2.0(Pavlick et al., 2015)에 따라 대상 단어와 동일한 구문 범주에 속하는 고품질 의역 규칙(단어의 경우 품질 점수 ≥3.5, 구의 경우 ≥4.0)입니다.\n",
        "\n",
        "**<결과>**\n",
        "\n",
        "**<논문 Table 5>**는 각 대상에 대해 생성된 대체 수에 대한 SimplePPDB와 SimplePPDB++의 비교, 후보 대체의 최종 순위 목록에 대한 평균 평균 정밀도 및 precision@1을 보여줍니다.\n",
        "\n",
        "이것은 SimplePPDB++와 SimplePPDB를 공정하고 직접적으로 비교한 것입니다. 두 방법 모두 PPDB에서 잠재적 후보로 동일한 패러프레이즈 규칙에 액세스할 수 있기 때문입니다.\n",
        "\n",
        "SimplePPDB++를 생성할 때 사용한 더 나은 NRR 모델은 이전 버전의 SimplePPDB보다 개선된 선택 및 단순화된 패러프레이즈 규칙 순위를 허용합니다. 추가 참조로 우리는 평가 설계에 의해 PPDB가 전체 범위를 포함하는 동안 정밀도 비교에 중점을 둔 (Pavlick and Callison-Burch, 2016) 기반의 다른 기존 방법에 대한 측정도 포함합니다.\n",
        "\n",
        "### **[4] Complex Word Identification**\n",
        "\n",
        "***\n",
        "**<논문 Table 6> 표가 삽입됩니다.**\n",
        "\n",
        "**설명 : 복잡한 영어 단어 식별을 위한 두 개의 데이터 세트에 대한 평가. 단어 복잡도 사전(WC)을 활용하는 우리의 접근 방식은 가장 가까운 중심(Yimam et al., 2017) 및 SV000gg(Paetzold and Specia, 2016b) 시스템을 개선합니다. 각 열의 최고 성능 수치는 굵은 글꼴로 표시하고 두 번째 최고는 밑줄로 표시합니다.**\n",
        "***\n",
        "**<논문 Table 7> 표가 삽입됩니다.**\n",
        "\n",
        "**설명 : CWI 데이터 세트의 통계 – 우리의 단어-복잡성 사전에 대한 대상 단어/구의 총 수, 고유 대상 수 및 어휘 내(IV) 비율**\n",
        "***\n",
        "\n",
        "복잡한 단어 식별(CWI)은 문장에서 단순화해야 하는 어려운 단어를 식별합니다. Shardlow(2014)에 따르면 이 단계는 어려운 단어를 간과하거나 간단한 단어를 과도하게 단순화하는 것과 같은 실수를 방지하여 단순화 시스템을 개선할 수 있습니다.\n",
        "\n",
        "이 섹션에서는 인간의 평가를 최첨단 시스템에 주입하여 단어 복잡도 사전이 CWI 작업에 어떻게 도움이 되는지 보여줍니다.\n",
        "\n",
        "**<데이터>**\n",
        "\n",
        "과제는 문장에서 대상 단어/구문이 '단순'인지 '복잡'인지 예측하는 것으로, 예를 들면 다음과 같습니다.\n",
        "\n",
        "***\n",
        "**Nine people were killed in the bombardment.**\n",
        "***\n",
        "\n",
        "우리는 두 가지 데이터 세트에 대해 실험을 수행합니다. (i) Semeval 2016 CWI 공유 작업 데이터 세트(Paetzold and Specia, 2016a)는 CWI 시스템을 평가하는 데 널리 사용되었으며 Wikipedia의 2,237 교육 및 88,221 테스트 인스턴스를 포함합니다. 및 (ii) CWIG3G2 데이터 세트(Yimam et al., 2017), 영어 단일 언어 CWI 2018 공유 작업 데이터 세트(Yimam et al., 2018)라고도 하며 Wikipedia에서 27,299개의 교육, 3,328개의 개발 및 4,252개의 테스트 인스턴스로 구성됩니다. 그리고 뉴스 기사. **<논문 Table 7>**은 두 CWI 데이터 세트에 대한 단어 복잡도 사전의 적용 범위를 보여줍니다.\n",
        "\n",
        "**<기존 방식과의 비교>**\n",
        "\n",
        "우리는 두 가지 첨단 CWI 시스템을 고려합니다.\n",
        "\n",
        "1. (Yimam et al., 2017)에서 제안된 가장 가까운 중심 분류기 단순 Wikipedia 코퍼스 및 Google 1T 코퍼스를 기능으로 제공\n",
        "2. 어휘, 형태, 연어 및 의미 기능의 조합으로 훈련된 이진 분류기의 앙상블인 SV000gg(Paetzold and Specia, 2016b).\n",
        "\n",
        "후자는 Semeval 2016 CWI 데이터 세트에서 가장 성능이 좋은 시스템입니다.\n",
        "또한 Simple Wikipedia에서 단어 길이, 단어 의미 수 및 빈도를 사용하는 임계값 기반 기준선과 비교합니다.\n",
        "\n",
        "**<단어 복잡성 어휘 활용>**\n",
        "\n",
        "§3.2에 설명된 추가 기능으로 단어 복잡도 사전을 통합하여 SV000gg 및 최근접 중심 분류기를 향상시킵니다.\n",
        "\n",
        "LEXenstein 툴킷의 SV000gg 구현에 수정 사항을 추가하고 가장 가까운 중심 분류기에 자체 구현을 사용했습니다.\n",
        "\n",
        "또한 단어복잡성 어휘를 개별적으로 평가하기 위해 인간 평가만 입력으로 사용하는 의사결정 트리 분류기를 훈련합니다(W C 전용). 이는 인간 평가에 대한 임계값을 학습하는 것과 같습니다.\n",
        "\n",
        "**<결과>**\n",
        "\n",
        "향상된 접근 방식(SV000gg+W C 및 NC+W C)과 사전 전용 접근 방식(WC 전용)을 최첨단 및 기준 임계값 기반 방법과 비교합니다.\n",
        "\n",
        "성능 측정을 위해 F-점수와 정확도, G-점수, 정확도와 재현율의 조화 평균을 사용합니다. G-score는 Semeval 2016의 CWI 작업의 공식 지표입니다.\n",
        "\n",
        "**<논문 Table 6>**는 wordcomplexity lexicon이 세 가지 메트릭 모두에서 SV000gg와 Nearest centroid classifier의 성능을 향상시킨다는 것을 보여줍니다.\n",
        "\n",
        "개선은 p < 0.01인 paired bootstrap test에 따라 통계적으로 유의미합니다.\n",
        "\n",
        "word-complexity lexicon 단독(WC 전용)은 CWIG3G2 데이터 세트에서 만족스럽게 수행되며, 이는 시간과 공간 효율성이 매우 높은 간단한 테이블 조회 방식입니다.\n",
        "\n",
        "CWI SemEval 2016 데이터 세트의 경우 W C 전용 접근 방식이 최고의 정확도와 Fscore를 제공하지만 이는 데이터 세트의 편향된 분포에 기인할 수 있습니다(테스트 인스턴스의 5%만 '복잡'함).\n",
        "\n",
        "## **5. Related Work**\n",
        "\n",
        "### **[1] Lexical simplification (어휘 단순화)**\n",
        "\n",
        "어휘 단순화에 대한 이전 작업은 단어 복잡성을 평가하기 위해 어휘 및 말뭉치 기반 기능에 따라 다릅니다. 복잡한 단어 식별의 경우 크게 두 가지 연구 라인이 있습니다.\n",
        "\n",
        "1. 큰 말뭉치에 대한 빈도 기반 임계값 학습(Shardlow, 2013b)\n",
        "2. 어휘 및 언어 모델 기능의 조합에 대한 분류기 앙상블 훈련(Shardlow, 2013a; Paetzold 및 Specia, 2016a; Yimam et al., 2017; Kriz et al., 2018)\n",
        "\n",
        "교체 순위도 비슷한 추세를 따릅니다. Biranet al. (2011) 및 Bott et al. (2012) Wikipedia 및 Simple Wikipedia의 단어 길이와 단어 빈도를 기반으로 하는 단순성 측정을 사용했습니다. Kajiwaraet al. (2013) WordNet 유사성 측정을 Simple Wikipedia 빈도와 결합했습니다.\n",
        "\n",
        "Glavas와 ˇ Stajner(ˇ 2015)는 빈도, 언어 모델 및 의미론적 유사성 특성 모음에 의해 생성된 순위를 평균화했습니다. Horn et al. (2014) 코퍼스 기반 기능에 대해 SVM 분류기를 훈련했습니다.\n",
        "\n",
        "최근에야 연구자들은 단순화 작업에 신경망을 적용하기 시작했습니다. 우리가 아는 한, Paetzold와 Specia(2017)의 작업은 언어 모델 확률 기능이 있는 피드-포워드 네트워크를 사용하는 어휘 단순화를 위한 최초의 신경 모델입니다.\n",
        "\n",
        "우리의 NRR 모델은 숫자 특징을 벡터화하고 15,000개 영어 단어의 단어 복잡도 사전을 사용하여 인간의 판단을 포함하는 최초의 쌍별 신경 순위 모델입니다.\n",
        "\n",
        "어휘 단순화 외에도 관련 연구의 또 다른 라인은 통계 또는 신경 기계 번역(MT) 접근 방식을 사용하는 문장 단순화입니다(Xu et al., 2016; Nisioi et al., 2017; Zhang and Lapata, 2017; Vu et al., 2018). ; Guo et al., 2018).\n",
        "\n",
        "PPDB의 의역 규칙을 문장 단순화(Xu et al., 2016) 및 이중 언어 번역(Mehdizadeh Seraj et al., 2015)을 위한 통계적 MT에 통합하는 것이 가능함을 보여주었지만 SimplePPDB++를 신경 MT에 주입하는 방법은 아직 공개된 연구 문제로 남아 있습니다.\n",
        "\n",
        "### **[2] 단순화를 위한 Lexica**\n",
        "\n",
        "단순화를 위해 수동으로 생성된 사전을 사용하려는 이전 시도가 있었습니다.\n",
        "\n",
        "예를 들어, Elhadad와 Sutaria(2007)는 UMLS 어휘집(Bodenreider, 2007)을 사용했는데, 이는 기술 의학 용어의 저장소입니다. Eharaet al. (2010) 각 사용자의 어휘 친숙도를 연구하기 위해 영어가 모국어가 아닌 사용자에게 12,000개의 영어 단어에 해당하는 객관식 질문에 답하도록 요청했습니다. Kaji et al. (2012) 및 Kajiwara et al. (2013)은 초등학교 교과서를 기반으로 한 5,404개의 일본어 단어 사전을 사용했습니다. Xu et al. (2016)은 3,000개의 가장 일반적인 영어 단어 목록을 사용했습니다. Lee and Yeung(2018)은 다양한 복잡성 수준의 어휘 목록 앙상블을 사용했습니다.\n",
        "\n",
        "그러나 우리가 아는 한, 자동 단순화 시스템에서 상당한 개선을 보여준 인간의 판단으로 큰 단어 복잡도 어휘를 수동으로 구축하는 것에 대한 이전 연구는 없습니다.\n",
        "\n",
        "우리는 감정 단어 사전(Mohammad and Turney, 2013)과 행복 단어 사전(Dodds et al., 2011, 2015)의 성공에 고무되었습니다.\n",
        "\n",
        "### **[3] Vectorizing features (벡터화 기능)**\n",
        "\n",
        "특징 비닝은 비신경 기계 학습 모델에서 더 일반적으로 사용되는 연속 값을 이산화하기 위한 표준 특징 엔지니어링 및 데이터 처리 방법입니다.\n",
        "\n",
        "우리의 작업은 신경 모델의 특징 양자화(Sil et al., 2017; Liu et al., 2016)와 POS 태그를 특징으로 포함하는 신경 종속성 구문 분석(Chen and Manning, 2014)에 대해 논의한 엔티티 연결에 대한 최근 작업에서 크게 영감을 받았습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWKjnQaHB4vf"
      },
      "source": [
        "## **6. Conclusion (결론)**\n",
        "\n",
        "우리는 새로운 신경 가독성 순위 모델을 제안하고 다양한 어휘 단순화 작업에서 최첨단보다 상당한 성능 향상을 보여주었습니다.\n",
        "\n",
        "우리는 15,000개의 영어 단어로 구성된 수동으로 구성된 단어-복잡성 어휘와 품질 및 단순성 등급을 가진 천만 개 이상의 의역 규칙으로 구성된 자동으로 구성된 어휘 리소스 SimplePPDB++를 출시합니다.\n",
        "\n",
        "향후 작업을 위해 특정 도메인, 다양한 대상 사용자 및 언어를 포함하도록 사전을 확장하고자 합니다.\n",
        "\n",
        "## **7. Acknowledgments (감사의 말)**\n",
        "\n",
        "사려 깊은 논평을 해주신 익명의 심사위원께 감사드립니다. 귀중한 토론에 대해 Avirup Sil와 Anastasios Sidiropoulos에게 감사드립니다. Sanja\n",
        "ˇ를 공유한 Stajner와 Seid Muhie Yimam\n",
        "코드와 데이터.\n",
        "\n",
        "Jeniya Tabassum, Ashutosh Baheti, Wuwei Lan, Fan Bai, Alexander Konovalov, Chaitanya Kulkarni, Shuaichen Chang, Jayavardhan Reddy, Abhishek Kumar 및 Shreejit Gangadharan 주석에게도 감사드립니다.\n",
        "\n",
        "이 자료는 IIS-1822754 및 IIS1755898 보조금으로 NSF가 후원하는 연구를 기반으로 합니다. 이 간행물에 포함된 견해와 결론은 저자의 것이며 NSF 또는 미국 정부의 공식 정책이나 승인을 나타내는 것으로 해석되어서는 안 됩니다."
      ]
    }
  ]
}